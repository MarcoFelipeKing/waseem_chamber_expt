---
title: "Untitled"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(dplyr,readxl,tidyr,ggplot2,deSolve)
```

## Wassem Air and surface sampling experiment

Currently the estimation of $E/l$ during steady state is implemented using ABC which gives a correlation.

## TODO

- Surface concentrations which are currently cfu/cm$^2$ per hour $\lambda_d$ (loss from deposition).
- How long was each petri dish open?


```{r read in data}
df <- read_xlsx(path = "../data/chamber_expt_data.xlsx",sheet = 1) %>% janitor::clean_names()
df %>% 
  rename("position"="position_air_inlet_1_or_outlet_2","ach"="ach_3_or_6",
         "air"="air_load_cfu_m3",
         "surface"="surface_load_cfu_m_2_h_1") %>% 
  mutate(position=as.factor(position),
         ach=as.factor(ach)) %>% 
  mutate(repeticion=rep(rep(1:12,each=5),2))->df

# unique(df$time_min)
```

## Summary data from the experiment

```{r}
df %>% 
  group_by(ach,position,time_min) %>% 
  summarise(M=mean(air,na.rm=TRUE),S=sd(air,na.rm=TRUE)) -> expt_data


expt_data %>% 
  filter(ach==3 & position==1) %>% 
  pull(M) ->data_M_3_1

expt_data %>% 
  filter(ach==3 & position==1) %>% 
  pull(S) ->data_S_3_1

expt_data %>% 
  filter(ach==6& position==1) %>% 
  pull(M) ->data_M_6_1

expt_data %>% 
  filter(ach==6& position==1) %>% 
  pull(S) ->data_S_6_1

expt_data %>% 
  filter(ach==3 & position==2) %>% 
  pull(M) ->data_M_3_2

expt_data %>% 
  filter(ach==3 & position==2) %>% 
  pull(S) ->data_S_3_2

expt_data %>% 
  filter(ach==6& position==2) %>% 
  pull(M) ->data_M_6_2

expt_data %>% 
  filter(ach==6& position==2) %>% 
  pull(S) ->data_S_6_2

```


```{r investigatory plots}



df %>% 
  ggplot()+
  geom_point(aes(x=air,y=surface,colour=position))+
  geom_smooth(aes(x=air,y=surface,colour=position),method="lm")+
  facet_grid(~ach,scales="free")+
  scale_y_continuous(trans="log10")+
  scale_x_continuous(trans="log10")+
  ylab("Surface concentration")+
  xlab("Airborne concentration")+
  scale_color_brewer(palette = "Set1")+
  hrbrthemes::theme_ipsum()+
  theme(legend.position="")->a
  

df %>% 
  ggplot()+
  geom_point(aes(x=time_min,y=air,colour=position))+
  # geom_line(aes(x=time_min,y=surface,colour=as.factor(repeticion)))
  geom_smooth(aes(x=time_min,y=air,colour=position),method="lm")+
  facet_grid(~ach)+
  scale_y_continuous(trans="log10")+
  # scale_x_continuous(trans="log10")+
  ylab("Air concentration (cfu m3)")+
  xlab("Time (minutes)")+
  scale_color_brewer(palette = "Set1")+
  hrbrthemes::theme_ipsum()+
  theme(legend.position="") ->b
  b
ggpubr::ggarrange(a,b,nrow = 2)



```

```{r}

df %>% 
  ggplot()+
  geom_point(aes(x=time_min,y=surface,colour=position))+
  # geom_line(aes(x=time_min,y=surface,colour=as.factor(repeticion)))
  geom_smooth(aes(x=time_min,y=surface,colour=position),method="lm")+
  facet_grid(~ach)+
  scale_y_continuous(trans="log10")+
  # scale_x_continuous(trans="log10")+
  ylab("Surface concentration (¿¿)")+
  xlab("Time (minutes)")+
  scale_color_brewer(palette = "Set1")+
  hrbrthemes::theme_ipsum()+
  theme(legend.position="")
```





# Model relating airborne and surface concentrations

$$\dfrac{d C}{d t}=\dfrac{E}{V}-\lambda C$$

where $\lambda=\lambda_i+\lambda_d+\lambda_v $, which is a combination of inactivation (which includes efficiency of sampling), deposition and removal by ventilation.

Steady state $$ C=-\dfrac{E}{V\lambda}$$. Need to know E with some more certainty. 


This has an analytical solution of the form:

$$ C(t)=\dfrac{E}{V}(1-e^{-\lambda t})+ C_0 e^{-\lambda t} $$

Where $C_0$ is the initial concentration of particles. So the general formulation is represented by:

$$ C(t)=\dfrac{E}{V}(1-e^{-(\lambda_i+\lambda_d+\lambda_v) t})+ C_0 e^{-(\lambda_i+\lambda_d+\lambda_v) t} $$


```{r Distance function}

Distance<-function(x,y,s){  # computes the Euclidean distance between two lists of the same length
  if (length(x) == length(y)){
     #sqrt(sum((x-y)/(s))^2) #sqrt is slow
    (sum((x-y)/(s)))^2 #This is faster than abs(dist(rbind(x/s,y/s))) by 1 order of magnitude
  }
  else{
    print( 'vectors are not the same length')}
}

```


## ODE solver function

```{r ODE function}
# ode_model <- function(times, initial_contamination, parameters){
#   with(
#     as.list(c(initial_contamination, parameters)),{
#       # dContamination <- Contamination*r*(1-Contamination/C)-d*exp(-g*times)*Contamination
#       dContamination <- (1-Contamination/C)*r-d*exp(-g*times)*Contamination
#       return(list(dContamination))
#     }
#   )
# }

ode_model<- function(t, y, parameters){
  with(
    as.list(c(y, parameters)),{
      dContamination <- E/(32.25)-l*Contamination
      return(list(dContamination))
    }
  )
}
```

## Deterministic run function

```{r deterministic run function}
# 65  80  95 110 125

deterministic_run<-function(precision,initial_contamination,parameters){
  tmax = 3
  times = seq(0, tmax, length.out = precision) #precision+1

#sim=odeint(ode_model,initial_contamination,times,args=(r,C,d,g,l))
#parameters=c(r,C,d,g,l)
sim<- ode(initial_contamination, times, ode_model, parameters, method = "radau",atol = 1e-4, rtol = 1e-4)
# num_at_0=sim[int(precision*0.1/50.0)]
# num_at_1=sim[(precision*65/tmax/60),2]
num_at_2=sim[(precision*80/tmax/60),2]
num_at_4=sim[(precision*95/tmax/60),2]
num_at_6=sim[(precision*110/tmax/60),2]
num_at_16=sim[(precision*125/tmax/60),2]
# num_at_18=sim[(precision*18/tmax),2]
# num_at_20=sim[(precision*20/tmax),2]
# num_at_22=sim[(precision*22/tmax),2]
# num_at_24=sim[(precision*24/tmax),2]

return(cbind(num_at_2,num_at_4,num_at_6,num_at_16))
# return(cbind(num_at_2,num_at_4,num_at_6,num_at_16,num_at_18,num_at_20,num_at_22,num_at_24))
}
```

## Steady state:

Steady state $$ C=-\dfrac{E}{V\lambda}$$. Need to know E with some more certainty.


```{r}
C_star <- function(parameters){
  E=parameters[[1]]
  l=parameters[[2]]
  C=E/(32.25*l)
  return(rep(C,5))
}
```

# Parallel version - Non-C
This is the parallel implementation usingg the furrrr framework with 4 worker cores
```{r parallel implementation with furrr}
##################################################################################################################
## Applying the ABC rejection algorithm

# library(foreach)
# library(doParallel)
# cores=detectCores()
# cl <- makeCluster(cores[1]-1) #not to overload your computer
# registerDoParallel(cl)

simulate_function<-function(a){
  # set.seed(seed = TRUE)
  .Random.seed <- a
  #set up empty distances vector
  distances<-c()
  precision=5000 #this is delta t
  sample_size = 200
  #parameter_sample <- c()
  parameter_sample<- matrix(data=NA,nrow=1,ncol=5)
  total_trials=0  #Starts the counter of run trials
  accepted_trials=0 #Starts the counter for accepted trial numbers, don't change


  #Loop to sample values until met the sample size
while (NROW(parameter_sample) <= sample_size){
#foreach(total_trials=1:2, .packages=c("deSolve")) %dopar% {
  
  # The prior distributions we use are d ~ U(0.001,10.0), C ~ U(200,1200), r ~ U(0.001,1.0), g ~ U(0.001,1.0). 
  # We begin by sampling from these distributions and simulating the process
trial_E = runif(1,1E2,1e3)
trial_l_3_1 = runif(1,0.1,3e1)
trial_l_3_2 = runif(1,0.1,3e1)
trial_l_6_1 = runif(1,0.1,3e1)
trial_l_6_2 = runif(1,0.1,3e1)
total_trials=total_trials+1.0
#print(total_trials)
parameters_3_1=c(E=trial_E,
             l_3_1=trial_l_3_1) 
parameters_3_2=c(E=trial_E,
             l_3_2=trial_l_3_2) 
parameters_6_1=c(E=trial_E,
             l_6_1=trial_l_6_1) 
parameters_6_2=c(E=trial_E,
            l_6_2=trial_l_6_2)

 
#Learn data from 3_1
 one_run = C_star(parameters = parameters_3_1)
 euclidean_distance = abs(dist(rbind(one_run,data_M_3_1)))

#Learn data from 3_2
 one_run = C_star(parameters = parameters_3_2)
 euclidean_distance = abs(dist(rbind(one_run,data_M_3_2)))+euclidean_distance

#Learn data from 6_1
 one_run = C_star(parameters = parameters_6_1)
 euclidean_distance = abs(dist(rbind(one_run,data_M_6_1)))+euclidean_distance
 
#Learn data from 6_2
 one_run = C_star(parameters = parameters_6_2)
 euclidean_distance = abs(dist(rbind(one_run,data_M_6_2)))+euclidean_distance
 
 
# parameters <- c(C = trial_C, d = trial_d, g=trial_g,r=trial_r); #For C code
# one_run = deterministic_run(precision,initial_contamination,parameters)#


# Now we find the Euclidean distance between the simulated output and the
# experimental results. delta is the threshold that the Euclidean distance
# must be less than for us to accept the trial parameters into our sample.
delta = 32000#dictates distance


#Distance(one_run, experimental_data,s)# #Distance(one_run, experimental_data,s)#_noP2)
#print(euclidean_distance)# print(parameter_sample,euclidean_distance)
#print(total_trials)

if (euclidean_distance < delta){
  #parameter_sample = parameter_sample[!is.na(parameter_sample)];
  parameter_sample=rbind(parameter_sample, c(trial_E,trial_l_3_1,trial_l_3_2,trial_l_6_1,trial_l_6_1))
  distances=rbind(distances,euclidean_distance)
  accepted_trials=accepted_trials+1.0
   print(paste0("Trial number accepted: ",accepted_trials))
}
  #else{
  #  print(euclidean_distance)
  #  }

}
  
parameter_sample<-parameter_sample[order(distances), ]
parameter_sample<-parameter_sample%>%as.data.frame()#%>%set_colnames(c("r", "C", "d","g","l"))
colnames(parameter_sample)<-c("E", "l_3_1","l_3_2","l_6_1","l_6_2")
# return(parameter_sample)
print(paste("Summary of distances: ",distances %>% summary()))
print(paste("Percentage of accepted trials: ",accepted_trials/total_trials*100))

return(parameter_sample)
# return(list("parameter_sample" = parameter_sample, "distances" = distances))
}

# Parallel implementation

# print(paste0("Percentage of trials accepted: ",(100*accepted_trials/total_trials)))
# #Order the distances and then the parameter sample
# parameter_sample<-parameter_sample[order(distances), ]
# parameter_sample<-parameter_sample%>%as.data.frame()#%>%set_colnames(c("r", "C", "d","g","l"))
# colnames(parameter_sample)<-c("r", "C", "d","g","l")

#2 %>% purrr::rerun()
# Run in parallel
require(future)
plan(multisession, workers = 6)
# temp.list<-lapply(X = 1:4,FUN = simulate_function)

RNGkind("L'Ecuyer-CMRG")
set.seed(42)
seeds <- list(.Random.seed)
temp.list<-furrr::future_map(.x = 1:6,.f = simulate_function)

# Reset to running sequentially
plan(sequential)



temp.list %>%
  bind_rows() %>% 
  # select(parameter_sample) %>% 
  drop_na() %>% 
  unnest()  ->parameter_sample
write.csv(parameter_sample,"../Data/parameter_sample.csv",row.names = FALSE)

```



# Plots - Serial

```{r parameter sample plots}
parameter_sample %>% 
  pivot_longer(c(E,l),names_to="Parameter") %>% 

# df_tidy<-gather(parameter_sample[,-5], Parameter, value)
ggplot(aes(x=value))+
  geom_histogram(fill="#69b3a2",bins = 20,colour="gray")+
  ggpubr::theme_pubclean()+
  facet_wrap(~Parameter,ncol = 2,scales = "free")

parameter_sample %>% 
  ggplot()+
  geom_point(aes(x=E,y=l),alpha=0.2)

  
```

```{r Trajectory plots}
E_m=mean(parameter_sample$E,na.rm=TRUE)
l_m=mean(parameter_sample$l,na.rm=TRUE)
C_star(parameters = c(E_m,l_m))[1]



```

